//!
//! \file skl_spsc_unidirectional_ring
//!
//! \brief Wait-free single producer single consumer unidirectional ring buffer
//!
//! \details Provides a lock-free SPSC queue where the producer enqueues objects
//!          and the consumer processes them. Objects flow in one direction only
//!          (producer -> consumer).
//!
//! \note Supports optional huge pages allocation for improved performance
//! \note When using huge pages, call allocate_internal_storage() before use
//!
//! \license Licensed under the MIT License. See LICENSE for details.
//!
#pragma once

#include "skl_int"
#include "skl_def"
#include "skl_atomic"
#include "skl_utility"
#include "skl_huge_pages"
#include "skl_traits/conditional_t"

namespace skl {
//! [WaitFree] Single Consumer Single Producer, unidirectional ring buffer (queue)
template <typename _Object, u64 _Size, bool _UseHugePages>
    requires(__is_nothrow_constructible(_Object))
struct SKL_CACHE_ALIGNED spsc_unidirectional_ring_t {
    static constexpr u64 Size = _Size;
    static constexpr u64 Mask = _Size - 1U;
    static_assert((Size > 0ULL) && (0U == (Size & Mask)), "_Size must be a power of 2!");

    //! Whether to use huge pages for the internal buffer allocation
    static constexpr bool CUseHugePages   = _UseHugePages;
    static constexpr u64  CHugePagesCount = integral_ceil(sizeof(_Object) * Size, huge_pages::CHugePageSize);

    //! Storage type for the internal buffer
    using storage_t = conditional_t<_UseHugePages, _Object*, _Object[Size]>;

    SKL_NO_MOVE_OR_COPY(spsc_unidirectional_ring_t);

    spsc_unidirectional_ring_t() noexcept = default;
    ~spsc_unidirectional_ring_t() noexcept {
        if constexpr (_UseHugePages) {
            if (nullptr != m_objects) {
                free_internal_storage();
            }
        }
    }

    //! Allocate the internal storage
    //! \remark Must be called before any other operation if _UseHugePages is true
    void allocate_internal_storage() noexcept
        requires(_UseHugePages)
    {
        m_objects = reinterpret_cast<_Object*>(huge_pages::skl_huge_page_alloc(CHugePagesCount));
        SKL_ASSERT_PERMANENT(nullptr != m_objects);

        // Placement new all objects
        if constexpr (__is_trivially_constructible(_Object)) {
            skl_core_zero_memory(m_objects, sizeof(_Object) * Size);
        } else {
            for (u64 i = 0U; i < Size; ++i) {
                new (&m_objects[i]) _Object();
            }
        }
    }

    //! Free the internal storage
    //! \remark Must be called to free resources if _UseHugePages is true
    //! \remark Automatically called in the destructor
    void free_internal_storage() noexcept
        requires(_UseHugePages)
    {
        SKL_ASSERT_PERMANENT(nullptr != m_objects);

        // Destruct all objects
        if constexpr (false == __is_trivially_destructible(_Object)) {
            for (u64 i = 0U; i < Size; ++i) {
                m_objects[i].~_Object();
            }
        }

        huge_pages::skl_huge_page_free(m_objects, CHugePagesCount);
        m_objects = nullptr;
    }

    //! Does the internal storage exist
    [[nodiscard]] bool has_internal_storage() const noexcept
        requires(_UseHugePages)
    {
        return nullptr != m_objects;
    }

    //! Get the internal buffer
    //! \remark only use this method when the producer and consumer are not running
    //! \remark eg. use it to prepare the objects in the buffer in a specific way before use
    [[nodiscard]] _Object* buffer() noexcept {
        return m_objects;
    }

    //! [SCSP] {Producer} Allocate new object
    //! \remark call submit() to submit all allocated objects to be visible to the consumer
    //! \returns nullptr if no object available for allocation
    [[nodiscard]] _Object* allocate() noexcept {
        if (0U == free_count()) {
            return nullptr;
        }

        const auto alloc_index = m_allocate_head++;
        return &m_objects[(alloc_index & Mask)];
    }

    //! [SCSP] {Producer} Allocate new object
    //! \remark call submit() to submit all allocated objects to be visible to the consumer
    //! \remark asserts free_count() > 0
    [[nodiscard]] _Object& allocate_checked() noexcept {
        SKL_ASSERT(0U < free_count());
        const auto alloc_index = m_allocate_head++;
        return m_objects[(alloc_index & Mask)];
    }

    //! [SCSP] {Producer} Allocate objects in bulk
    //! \remark call submit() to make all allocated objects visible to the consumer in a single (release) atomic operation
    //! \returns false the queue is full, no \p f_count free objects for allocation
    [[nodiscard]] bool allocate_bulk(_Object** f_out_objects, u32 f_count) noexcept {
        if (f_count > free_count()) {
            return false;
        }

        const auto start = m_allocate_head;
        for (u64 i = 0ULL; i < f_count; ++i) {
            f_out_objects[i] = &m_objects[(start + i) & Mask];
        }
        m_allocate_head += f_count;

        return true;
    }

    //! [SCSP] {Producer} Allocate objects in bulk
    //! \remark call submit() to make all allocated objects visible to the consumer in a single (release) atomic operation
    //! \remark asserts free_count() >= \p f_count
    void allocate_bulk_checked(_Object** f_out_objects, u32 f_count) noexcept {
        SKL_ASSERT(f_count <= free_count());

        const auto start = m_allocate_head;
        for (u64 i = 0ULL; i < f_count; ++i) {
            f_out_objects[i] = &m_objects[(start + i) & Mask];
        }
        m_allocate_head += f_count;
    }

    //! [SCSP] {Producer} Get count of free objects
    [[nodiscard]] u64 free_count() noexcept {
        m_cached_tail = m_queue_tail.load_acquire();

        const auto delta = m_allocate_head - m_cached_tail;
        return Size - delta;
    }

    //! [SCSP] {Producer} Get buffer usage count
    [[nodiscard]] u64 usage_count() noexcept {
        const auto free = free_count();
        return Size - free;
    }

    //! [SCSP] {Producer} Get allocated (pending submit) objects count
    [[nodiscard]] u64 allocated_count() const noexcept {
        return m_allocate_head - m_queue_head.load_relaxed();
    }

    //! [SCSP] {Producer} Submit all allocated objects (if any)
    void submit() noexcept {
        const auto head = m_queue_head.load_relaxed();
        SKL_ASSERT_CRITICAL(m_allocate_head >= head);
        if (m_allocate_head > head) {
            m_queue_head.store_release(m_allocate_head);
        }
    }

    //! [SCSP] {Producer} Pop allocated object
    //! \remark asserts (0U < allocated_count())
    void pop_allocation() noexcept {
        SKL_ASSERT_CRITICAL(0U < allocated_count());
        --m_allocate_head;
    }

    //! [SCSP] {Consumer} Dequeue objects for processing (up to \p f_max_count)
    [[nodiscard]] u32 dequeue_burst(_Object** f_out_objects, u32 f_max_count) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = &m_objects[index];
            }

            m_process_head += result;
        }

        return result;
    }

    //! [SCSP] {Consumer} Dequeue objects for processing (up to \p f_max_count)
    [[nodiscard]] u32 dequeue_burst_by_value(_Object* f_out_objects, u32 f_max_count) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = m_objects[index];
            }

            m_process_head += result;
        }

        return result;
    }

    //! [SCSP] {Consumer} Dequeue objects for processing (up to \p f_max_count)
    //! \remark \p f_out_remaining will contain the count of remaining pending objects to be processed by the consumer
    [[nodiscard]] u32 dequeue_burst_hint(_Object** f_out_objects, u32 f_max_count, u32& f_out_remaining) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = &m_objects[index];
            }

            m_process_head += result;
        }

        //Save remaining
        f_out_remaining = delta - result;

        return result;
    }

    //! [SCSP] {Consumer} Dequeue objects for processing (up to \p f_max_count)
    //! \remark \p f_out_remaining will contain the count of remaining pending objects to be processed by the consumer
    [[nodiscard]] u32 dequeue_burst_hint_by_value(_Object* f_out_objects, u32 f_max_count, u32& f_out_remaining) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = m_objects[index];
            }

            m_process_head += result;
        }

        //Save remaining
        f_out_remaining = delta - result;

        return result;
    }

    //! [SCSP] {Consumer} Process objects via \p _StaticFunctor
    //! \remark [](_Object& f_object) static noexcept -> void {}
    //! \return the count of processed objects
    template <u32 _MaxProcessCount, typename _StaticFunctor>
    [[nodiscard]] u32 process() noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < _MaxProcessCount); ++result) {
                const auto      index = (start + result) & Mask;
                _StaticFunctor::operator()(m_objects[index]);
            }
            m_process_head += result;
        }
        return result;
    }

    //! [SCSP] {Consumer} Process objects via \p _StaticFunctor
    //! \remark [](_Object& f_object) static noexcept -> void {}
    //! \return the count of processed objects
    template <typename _StaticFunctor>
    [[nodiscard]] u32 process(u32 f_max_process_count) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_process_count); ++result) {
                const auto      index = (start + result) & Mask;
                _StaticFunctor::operator()(m_objects[index]);
            }
            m_process_head += result;
        }
        return result;
    }

    //! [SCSP] {Consumer} Process objects via \p _Functor
    //! \remark [](_Object& f_object) noexcept -> void {}
    //! \return the count of processed objects
    template <typename _Functor>
    [[nodiscard]] u32 process(u32 f_max_process_count, _Functor& f_functor) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_process_count); ++result) {
                const auto index = (start + result) & Mask;
                f_functor(m_objects[index]);
            }
            m_process_head += result;
        }
        return result;
    }

    //! [SCSP] {Consumer} Free all processed objects (make slots available for producer)
    void free_processed() noexcept {
        m_queue_tail.store_release(m_process_head);
    }

    //! [SCSP] {Consumer} Free \p f_count processed objects (make slots available for producer)
    void free_processed(u32 f_count) noexcept {
        const auto current_tail = m_queue_tail.load_relaxed();
        SKL_ASSERT(f_count <= (m_process_head - current_tail));
        m_queue_tail.store_release(current_tail + f_count);
    }

    //! [SCSP] {Consumer} Get pending (available for processing) objects count
    [[nodiscard]] u64 pending_count() const noexcept {
        return m_queue_head.load_acquire() - m_process_head;
    }

    //! [SCSP] {Consumer} Get processed (not yet freed) objects count
    [[nodiscard]] u64 processed_count() const noexcept {
        return m_process_head - m_queue_tail.load_relaxed();
    }

private:
    SKL_CACHE_ALIGNED storage_t m_objects{}; //!< {Producer & Consumer} All queue objects

    SKL_CACHE_ALIGNED u64 m_allocate_head = 0ULL; //!< {Producer} Head to allocate at
    u64                   m_cached_tail   = 0ULL; //!< {Producer} Cached tail for free_count optimization

    SKL_CACHE_ALIGNED std::relaxed_value<u64> m_queue_head = 0ULL; //!< {Producer -> Consumer} Current enqueue head
    SKL_CACHE_ALIGNED std::relaxed_value<u64> m_queue_tail = 0ULL; //!< {Consumer -> Producer} Current freed tail

    SKL_CACHE_ALIGNED u64 m_process_head = 0ULL; //!< {Consumer} Current process head
};
} // namespace skl
