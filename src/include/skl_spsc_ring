//!
//! \file skl_spsc_ring
//!
//! \license Licensed under the MIT License. See LICENSE for details.
//!
#pragma once

#include <skl_int>
#include <skl_def>
#include <skl_atomic>
#include <skl_pair>
#include <skl_result>
#include <skl_utility>

//! Concept to detect the [reset() noexcept] method on _Object
template <typename _Object>
concept spsc_ring_reset_method_c = requires(_Object f_object) {
    { f_object.reset() } noexcept;
};

//! [WaitFree] Single Consumer Single Producer, bidirectional ring buffer (queue)
template <typename _Object, u64 _Size>
    requires(__is_nothrow_constructible(_Object))
struct SKL_CACHE_ALIGNED spsc_ring_t {
    static constexpr u64 Size = _Size;
    static constexpr u64 Mask = _Size - 1U;
    static_assert((Size > 0ULL) && (0U == (Size & Mask)), "_Size must be a power of 2!");

    SKL_NO_MOVE_OR_COPY(spsc_ring_t);

    constexpr spsc_ring_t() noexcept  = default;
    constexpr ~spsc_ring_t() noexcept = default;

    //! Get the internal buffer
    //! \remark only use this method when the producer and consumer are not running
    //! \remark eg. use it to prepare the objects in the buffer in a specific way before use
    [[nodiscard]] _Object* buffer() noexcept {
        return m_objects;
    }

    //! [SCSP] {Producer} Allocate new object
    //! \remark call submit() to submit all allocated objects to be visible to the consumer
    //! \returns nullptr if no object available for allocation
    [[nodiscard]] _Object* allocate() noexcept {
        if (0U == free_count()) {
            return nullptr;
        }

        const auto alloc_index = m_allocate_head++;
        return &m_objects[(alloc_index & Mask)];
    }

    //! [SCSP] {Producer} Allocate new object
    //! \remark call submit() to submit all allocated objects to be visible to the consumer
    //! \remark asserts free_count() > 0
    [[nodiscard]] _Object& allocate_checked() noexcept {
        SKL_ASSERT(0U < free_count());
        const auto alloc_index = m_allocate_head++;
        return m_objects[(alloc_index & Mask)];
    }

    //! [SCSP] {Producer} Allocate objects in bulk
    //! \remark call submit() to make all allocated objects visible to the consumer in a single (release) atomic operation
    //! \returns false the queue is full, no \p f_count free objects for allocation
    [[nodiscard]] bool allocate_bulk(_Object** f_out_objects, u32 f_count) noexcept {
        if (f_count > free_count()) {
            return false;
        }

        const auto start = m_allocate_head;
        for (u64 i = 0ULL; i < f_count; ++i) {
            f_out_objects[i] = &m_objects[(start + i) & Mask];
        }
        m_allocate_head += f_count;

        return true;
    }

    //! [SCSP] {Producer} Allocate objects in bulk
    //! \remark call submit() to make all allocated objects visible to the consumer in a single (release) atomic operation
    //! \remark asserts free_count() >= \p f_count
    void allocate_bulk_checked(_Object** f_out_objects, u32 f_count) noexcept {
        SKL_ASSERT(f_count <= free_count());

        const auto start = m_allocate_head;
        for (u64 i = 0ULL; i < f_count; ++i) {
            f_out_objects[i] = &m_objects[(start + i) & Mask];
        }
        m_allocate_head += f_count;
    }

    //! [SCSP] {Producer} Get count of free objects
    [[nodiscard]] u64 free_count() const noexcept {
        const u64 delta = m_allocate_head - m_queue_tail.load_acquire();
        SKL_ASSERT_CRITICAL(delta <= Size);
        return Size - delta;
    }

    //! [SCSP] {Producer} Get allocated objects count
    [[nodiscard]] u64 allocated_count() const noexcept {
        return m_allocate_head - m_queue_head.load_relaxed();
    }

    //! [SCSP] {Producer} Submit all allocated objects (if any)
    void submit() noexcept {
        const auto head = m_queue_head.load_relaxed();
        SKL_ASSERT_CRITICAL(m_allocate_head >= head);
        if (m_allocate_head > head) {
            m_queue_head.store_release(m_allocate_head);
        }
    }

    //! [SCSP] {Consumer} Free all processed objects
    void free_processed() noexcept {
        if (m_process_head > m_queue_tail.load_relaxed()) {
            m_queue_tail.store_release(m_process_head);
        }
    }

    //! [SCSP] {Producer} Pop allocated object
    //! \remark asserts (0U < allocated_count())
    template <bool _ResetObjectIfPossible = true>
    void pop_allocation() noexcept {
        SKL_ASSERT_CRITICAL(0U < allocated_count());
        if constexpr (_ResetObjectIfPossible && spsc_ring_reset_method_c<_Object>) {
            m_objects[(m_allocate_head - 1U) & Mask].reset();
        }

        --m_allocate_head;
    }

    //! [SCSP] {Consumer} Collect objects that need processing (up to \p f_max_count)
    [[nodiscard]] u32 dequeue_burst(_Object** f_out_objects, u32 f_max_count) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = &m_objects[index];
            }

            m_process_head += result;
        }

        return result;
    }

    //! [SCSP] {Consumer} Collect objects that need processing (up to \p f_max_count)
    //! \remark \p f_out_remaining will contain the count of remaining pending objects to be processed by the consumer
    [[nodiscard]] u32 dequeue_burst_hint(_Object** f_out_objects, u32 f_max_count, u32& f_out_remaining) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_count); ++result) {
                const auto index      = (start + result) & Mask;
                f_out_objects[result] = &m_objects[index];
            }

            m_process_head += result;
        }

        //Save remaining
        f_out_remaining = delta - result;

        return result;
    }

    //! [SCSP] {Producer} Process objects via \p _StaticFunctor
    //! \remark [](_Object& f_object) static noexcept -> void {}
    //! \return the count of processed objects
    template <typename _StaticFunctor>
    [[nodiscard]] u32 process_bulk(u32 f_max_process_count) noexcept {
        const auto start = m_process_head;
        const auto head  = m_queue_head.load_acquire();
        const auto delta = head - start;

        u32 result = 0U;
        if (0U < delta) {
            for (; (result < delta) && (result < f_max_process_count); ++result) {
                const auto      index = (start + result) & Mask;
                _StaticFunctor::operator()(m_objects[index]);
            }
            m_process_head += result;
        }
        return result;
    }

private:
    SKL_CACHE_ALIGNED u64 m_allocate_head                    = 0ULL; //!< {Producer} Head to allocate at
    SKL_CACHE_ALIGNED std::relaxed_value<u64> m_queue_head   = 0ULL; //!< {Producer -> Consumer} Current enqueue head
    SKL_CACHE_ALIGNED std::relaxed_value<u64> m_queue_tail   = 0ULL; //!< {Consumer -> Producer} Current enqueue tail
    SKL_CACHE_ALIGNED u64                     m_process_head = 0ULL; //!< {Consumer} Current process head

    SKL_CACHE_ALIGNED _Object m_objects[Size]; //!< {Producer & Consumer} All queue objects
};
